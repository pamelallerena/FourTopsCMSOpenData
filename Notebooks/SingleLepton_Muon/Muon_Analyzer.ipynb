{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91d8f18",
   "metadata": {},
   "source": [
    "# Notebook 1 - Simple Analyzer\n",
    "\n",
    "This notebook takes CMS OpenData nanoAOD files, applies some selection and make few simple plots. \n",
    "\n",
    "Expected output: Histograms with the event selection.\n",
    "\n",
    "\n",
    "Physics objects of interest: muons and jets. \n",
    "\n",
    "For more information: https://github.com/HEP-EPN/FourTopsCMSOpenData/wiki. \n",
    "\n",
    "To understand more about coffea (extremely useful): https://coffeateam.github.io/coffea/index.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b5f6f",
   "metadata": {},
   "source": [
    "Let's first load the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76764285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import vector; vector.register_awkward() \n",
    "import awkward as ak\n",
    "from coffea import processor\n",
    "from coffea.nanoevents import transforms\n",
    "from coffea.nanoevents.methods import base, vector\n",
    "from coffea.nanoevents import NanoAODSchema\n",
    "import hist\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89775383",
   "metadata": {},
   "source": [
    "For future use, let's define some global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0b1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ifile = uproot.open(\"root://eosuser.cern.ch//eos/user/a/algomez/tmpFiles/opendata_files/SingleElectron/cmsopendata2015_Run2015D_SingleElectron_MINIAOD_08Jun2016-v1_21.root\")\n",
    "#ifile[\"Events\"].keys()\n",
    "\n",
    "#events = NanoEventsFactory.from_root(\n",
    "#    \"https://xrootd-local.unl.edu:1094//store/user/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19980_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext3-v1_00000_0000.root\",\n",
    "#    schemaclass=NanoAODSchema.v6,\n",
    "#    metadata={\"dataset\": \"TT\"},\n",
    "#).events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6c4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"SingleMuon\"  \n",
    "\n",
    "# input files per process, set to e.g. 10 (smaller number = faster)\n",
    "N_FILES_MAX_PER_SAMPLE = 5\n",
    "\n",
    "### BENCHMARKING-SPECIFIC SETTINGS\n",
    "\n",
    "# chunk size to use\n",
    "CHUNKSIZE = 500_000\n",
    "\n",
    "# metadata to propagate through to metrics\n",
    "CORES_PER_WORKER = 2  # does not do anything, only used for metric gathering (set to 2 for distributed coffea-casa)\n",
    "\n",
    "# scaling for local setups with FuturesExecutor\n",
    "NUM_CORES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7cb6b1",
   "metadata": {},
   "source": [
    "NanoAOD datasets are stored in `data/ntuples_nanoaod.json` folder. This json file contains information about the number of events, process and systematic. The following function reads the json file and returns a dictionary with the process to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a76cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_fileset(n_files_max_per_sample,\n",
    "                      dataset=\"SingleMuon\",\n",
    "                      onlyNominal=False,\n",
    "                      ntuples_json=\"ntuples.json\"):\n",
    "    # using https://atlas-groupdata.web.cern.ch/atlas-groupdata/dev/AnalysisTop/TopDataPreparation/XSection-MC15-13TeV.data\n",
    "    # for reference\n",
    "    # x-secs are in pb\n",
    "    xsec_info = {\n",
    "        \"ttbar\": 831., ###396.87 + 332.97, # nonallhad + allhad, keep same x-sec for all\n",
    "       # \"single_top_s_chan\": 2.0268 + 1.2676,\n",
    "       # \"single_top_t_chan\": (36.993 + 22.175)/0.252,  # scale from lepton filter to inclusive\n",
    "       # \"single_top_tW\": 35.6 + 35.6, #37.936 + 37.906,\n",
    "        \"wjets\": 61526, ##61457 * 0.252,  # e/mu+nu final states\n",
    "        \"tttt\" : 0.009, \n",
    "        \"dyjets\": 6025,\n",
    "        \"data\": None\n",
    "    }\n",
    "\n",
    "    # list of files\n",
    "    with open(ntuples_json) as f:\n",
    "        file_info = json.load(f)\n",
    "    \n",
    "      # process into \"fileset\" summarizing all info\n",
    "    fileset = {}\n",
    "    for process in file_info.keys():\n",
    "        if process == \"data\":\n",
    "            file_list = file_info[process][dataset][\"files\"]\n",
    "            if n_files_max_per_sample != -1:\n",
    "                #file_list = file_list[:int(n_files_max_per_sample/10)]  # use partial set of samples\n",
    "                file_list = file_list[:]  # use partial set of samples\n",
    "\n",
    "            file_paths = [f[\"path\"] for f in file_list]\n",
    "            metadata = {\"process\": \"data\", \"xsec\": 1}\n",
    "            fileset.update({\"data\": {\"files\": file_paths, \"metadata\": metadata}})\n",
    "            \n",
    "\n",
    "        for variation in file_info[process].keys():\n",
    "            if onlyNominal & ~variation.startswith(\"nominal\"): continue\n",
    "            #print(variation)\n",
    "            file_list = file_info[process][variation][\"files\"]\n",
    "            if n_files_max_per_sample != -1:\n",
    "                #file_list = file_list[:n_files_max_per_sample]\n",
    "                file_list = file_list[:]# use partial set of samples\n",
    "\n",
    "            file_paths = [f[\"path\"] for f in file_list]\n",
    "            nevts_total = sum([f[\"nevts\"] for f in file_list])\n",
    "            metadata = {\"process\": process, \"variation\": variation, \"nevts\": nevts_total, \"xsec\": xsec_info[process]}\n",
    "            fileset.update({f\"{process}__{variation}\": {\"files\": file_paths, \"metadata\": metadata}})\n",
    "\n",
    "    return fileset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6873da60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'process': 'ttbar', 'variation': 'nominal', 'nevts': 97994442, 'xsec': 831.0}\n",
      "{'process': 'tttt', 'variation': 'nominal', 'nevts': 250000, 'xsec': 0.009}\n",
      "{'process': 'wjets', 'variation': 'nominal', 'nevts': 47161328, 'xsec': 61526}\n",
      "{'process': 'dyjets', 'variation': 'nominal', 'nevts': 8842520, 'xsec': 6025}\n",
      "{'process': 'data', 'xsec': 1}\n",
      "\n",
      "example of data information in fileset:\n",
      "{\n",
      "  'files': [root://eosuser.cern.ch//eos/user/p/pllerena/4topsoutput/ntuples/Run2015D_SingleMuon/Run2015D_SingleMuon_0.root, ...],\n"
     ]
    }
   ],
   "source": [
    "fileset = construct_fileset(N_FILES_MAX_PER_SAMPLE, dataset=DATA,\n",
    "                            onlyNominal=True, ntuples_json='../Tesis/ntuples.json') \n",
    "\n",
    "print(fileset[\"ttbar__nominal\"][\"metadata\"])\n",
    "print(fileset[\"tttt__nominal\"][\"metadata\"])\n",
    "print(fileset[\"wjets__nominal\"][\"metadata\"])\n",
    "print(fileset[\"dyjets__nominal\"][\"metadata\"])\n",
    "print(fileset[\"data\"][\"metadata\"])\n",
    "\n",
    "print(f\"\\nexample of data information in fileset:\\n{{\\n  'files': [{fileset['data']['files'][0]}, ...],\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17c2d880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.06215379122595"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6052*2256.38/156849\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "014f15d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number of Events: 74022265\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "with open('ntuples.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize a variable to store the total number of events\n",
    "total_events = 0\n",
    "\n",
    "# Loop through the files in the JSON data\n",
    "for file_info in data['data']['SingleMuon']['files']:\n",
    "    file_path = file_info['path']\n",
    "\n",
    "    # Open the ROOT file using uproot\n",
    "    with uproot.open(file_path) as f:\n",
    "        # Access the 'events' TTree and count the number of entries (events)\n",
    "        num_events = f['Events'].num_entries\n",
    "\n",
    "        # Print the file path and number of events\n",
    "        #print(f\"File: {file_path}, Number of Events: {num_events}\")\n",
    "\n",
    "        # Add the number of events to the total\n",
    "        total_events += num_events\n",
    "\n",
    "# Print the total number of events\n",
    "print(f\"\\nTotal Number of Events: {total_events}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed54bc2",
   "metadata": {},
   "source": [
    "## Analyzer\n",
    "\n",
    "Here is the main analyzer. Uses coffea/awkward to make the analysis.\n",
    "\n",
    "Advice: to understand how the selection is working, print the different arrays before and after the selections are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c01ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fourTopAnalysis(processor.ProcessorABC):\n",
    "    def __init__(self, DATASET):\n",
    "        \n",
    "        self.DATASET = DATASET\n",
    "\n",
    "        ### booking histograms\n",
    "        ## define categories\n",
    "        process_cat = hist.axis.StrCategory([], name=\"process\", label=\"Process\", growth=True)\n",
    "        variation_cat  = hist.axis.StrCategory([], name=\"variation\", label=\"Systematic variation\", growth=True)\n",
    "        \n",
    "        ## define bins (axis)\n",
    "        pt_axis = hist.axis.Regular( bins=500, start=0, stop=500, name=\"var\")\n",
    "        eta_axis = hist.axis.Regular( bins=40, start=-5, stop=5, name=\"var\")\n",
    "        num_axis = hist.axis.Regular( bins=20, start=0, stop=20, name=\"var\")\n",
    "        #Htb\n",
    "        htb_axis=hist.axis.Regular( bins=100, start=0, stop=1000, name=\"var\")\n",
    "        #Htratio\n",
    "        htrat_axis=hist.axis.Regular(bins=500,start=0, stop=1, name=\"var\")\n",
    "        #3rd-highest CSV\n",
    "        csv_axis=hist.axis.Regular(bins=100,start=0, stop=1, name=\"var\")\n",
    "        \n",
    "        \n",
    "        ## define a dictionary of histograms\n",
    "        self.hist_muon_dict = {\n",
    "            'muon_pt'  : (hist.Hist(pt_axis, process_cat, variation_cat, storage=hist.storage.Weight())),\n",
    "            'muon_eta' : (hist.Hist(eta_axis, process_cat, variation_cat, storage=hist.storage.Weight())),\n",
    "            'nmuons'   : (hist.Hist(num_axis, process_cat, variation_cat, storage=hist.storage.Weight())),\n",
    "            'jets_pt'  : (hist.Hist(pt_axis, process_cat, variation_cat, storage=hist.storage.Weight())),\n",
    "            'jets_eta' : (hist.Hist(eta_axis, process_cat, variation_cat, storage=hist.storage.Weight())),\n",
    "            'njets'    : (hist.Hist(num_axis, process_cat, variation_cat, storage=hist.storage.Weight())), \n",
    "            'nbjets'   : (hist.Hist(num_axis, process_cat, variation_cat, storage=hist.storage.Weight())),\n",
    "            'htb'      : (hist.Hist(htb_axis, process_cat, variation_cat, storage=hist.storage.Weight())), #variable for bdt\n",
    "            'htrat'    : (hist.Hist(htrat_axis, process_cat, variation_cat, storage=hist.storage.Weight())), #variable for bdt\n",
    "            'third_highest_csv': (hist.Hist(csv_axis, process_cat, variation_cat, storage=hist.storage.Weight())) #variable for bdt\n",
    "\n",
    "        }\n",
    "        \n",
    "        sumw_dict = {'sumw': processor.defaultdict_accumulator(float)\n",
    "        }\n",
    "        \n",
    "        # Variables para contar el flujo de cortes\n",
    "        self.cut_flow_counters = {\n",
    "            \"All Events\": 0,\n",
    "            \"Primary Vertex\": 0,\n",
    "            \"Trigger (IsoMu18)\": 0\n",
    "        }\n",
    "        \n",
    "        \n",
    "        ### define vectors for scatter plot\n",
    "        self.njets_signal_data = []\n",
    "        self.njets_background_data = []\n",
    "        self.nbjets_signal_data = []\n",
    "        self.nbjets_background_data = []\n",
    "        self.htb_signal_data = []\n",
    "        self.htb_background_data = []\n",
    "        self.htrat_signal_data = []\n",
    "        self.htrat_background_data = []\n",
    "        \n",
    "        self.njets_values=[]\n",
    "        self.nbjets_values=[]\n",
    "        self.htb_values=[]\n",
    "        self.htrat_values=[]\n",
    "        \n",
    "        self.njets_data = []\n",
    "        self.nbjets_data = []\n",
    "        self.htb_data = []\n",
    "        self.htrat_data = []\n",
    "\n",
    "    def process(self, events):\n",
    "\n",
    "        hists = self.hist_muon_dict.copy()\n",
    "\n",
    "        process = events.metadata[\"process\"]  # \"ttbar\" etc.\n",
    "\n",
    "    \n",
    "        if process != \"data\":\n",
    "            # normalization for MC\n",
    "            x_sec = events.metadata[\"xsec\"]\n",
    "            nevts_total = events.metadata[\"nevts\"]\n",
    "            lumi = 2256.38 # /pb integrated luminosity\n",
    "            xsec_weight = x_sec * lumi / nevts_total #L*cross-section/N\n",
    "        else:\n",
    "            xsec_weight = 1\n",
    "\n",
    "        events[\"pt_nominal\"] = 1.0\n",
    "\n",
    "        ### OBJECT SELECTION\n",
    "        \n",
    "        ### Object selection: Muon (Tight - muon id definition in nanoAOD does not work, have to define manual)\n",
    "        \n",
    "        muon_is_global= events.Muon.isGlobal == True\n",
    "        muon_is_tracker= events.Muon.isTracker == True\n",
    "        \n",
    "        loose_muon_selection = (events.Muon.pt > 10) & (abs(events.Muon.eta)<2.5) \\\n",
    "                                & ((muon_is_global) | (muon_is_tracker)) \\\n",
    "                                & (events.Muon.pfRelIso04_all < 0.25)\n",
    "        selected_muon_selection = (events.Muon.pt > 26) & (abs(events.Muon.eta)<2.1) \\\n",
    "                                    & ((muon_is_global) & (muon_is_tracker)) \\\n",
    "                                    & (events.Muon.nTrackerLayers > 5) & (events.Muon.nStations > 0) \\\n",
    "                                    & (abs(events.Muon.dxy) < 0.2) & (abs(events.Muon.dz) < 0.5) \\\n",
    "                                    & (events.Muon.pfRelIso04_all < .15)\n",
    "        #selected_muon_s\n",
    "        selected_muons = events.Muon[( loose_muon_selection & selected_muon_selection)]\n",
    "        veto_muons = events.Muon[( loose_muon_selection & ~selected_muon_selection)]\n",
    "        \n",
    "        ### Object selection: Jets\n",
    "        \n",
    "        jet_selection = (events.Jet.pt * events[\"pt_nominal\"] > 30) & (abs(events.Jet.eta) < 2.5) & (events.Jet.jetId > 1)\n",
    "        selected_jets = events.Jet[jet_selection]\n",
    "        nearest_lepton = selected_jets.nearest(selected_muons, threshold=.4)\n",
    "        selected_jets = selected_jets[ ~ak.is_none(nearest_lepton) ]\n",
    "        \n",
    "        ## the results of these 2 lines should be equivalent to the 2 lines above\n",
    "        #lepton_mask = ak.any(selected_jets.metric_table(selected_lepton, metric=lambda j, e: ak.local_index(j, axis=1) == e.jetIdx,), axis=2)\n",
    "        #selected_jets = selected_jets[~lepton_mask]\n",
    "        \n",
    "        selected_bjets = events.Jet[jet_selection & ~ak.is_none(nearest_lepton) & (events.Jet.btagCSVV2 >=0.8)]\n",
    "        selected_jets_nobjets = events.Jet[jet_selection & ~ak.is_none(nearest_lepton) & ~(events.Jet.btagCSVV2 >=0.8)]  ### this we might use it later\n",
    "        \n",
    "        \n",
    "        ### Object selection: Electron\n",
    "        \n",
    "        #Veto electrons \n",
    "        veto_electron_selection = (events.Electron.pt > 15) & (abs(events.Electron.eta) < 2.5) & (events.Electron.cutBased == 1)\n",
    "        \n",
    "        #tight electrons\n",
    "        selected_electron_selection = (events.Electron.pt > 30) & (abs(events.Electron.eta) < 2.1) & (events.Electron.cutBased == 4)\n",
    "        \n",
    "        selected_electrons = events.Electron[ selected_electron_selection & veto_electron_selection]\n",
    "        veto_electrons = events.Electron[ veto_electron_selection ]\n",
    "        \n",
    "        \n",
    "       ################\n",
    "        #### Event Selection\n",
    "        ################\n",
    "        \n",
    "        #self.cut_flow_counters[\"All Events\"][process] += len(events)\n",
    "        #primary_vertex= events.PV.npvsGood == True\n",
    "        \n",
    "        #event_filters=primary_vertex\n",
    "        #selected_events = events[event_filters]\n",
    "        #self.cut_flow_counters[\"Primary Vertex\"][process] += len(selected_events)\n",
    "        \n",
    "        event_filters = ( events.HLT.IsoMu18 == 1 ) \n",
    "       # selected_events = events[event_filters]\n",
    "        \n",
    "       # self.cut_flow_counters[\"Trigger (IsoMu18)\"][process] += len(selected_events)\n",
    "        \n",
    "        #number of primary vertex, at least one\n",
    "        #FIRST CUT\n",
    "        #primary_vertex=events.PV.npvs >= 1\n",
    "        \n",
    "        #event_filters = ( events.HLT.IsoMu18 == 1 )   #trigger selection (1 value per event)\n",
    "        \n",
    "        #event_filters = event_filters & primary_vertex\n",
    "        \n",
    "        selected_muon = (ak.count(selected_muons.pt, axis=1) == 1 ) \n",
    "        \n",
    "        event_filters = event_filters & selected_muon\n",
    "        \n",
    "        #Exactly zero additional loose muons\n",
    "        veto_muon = (ak.count(veto_muons.pt, axis=1 ) == 0 )\n",
    "\n",
    "        event_filters = event_filters & veto_muon\n",
    "        \n",
    "        #Exactly zero veto electrons\n",
    "        veto_electron = (ak.count(veto_electrons.pt, axis=1) == 0 )\n",
    "        \n",
    "        event_filters = event_filters & veto_electron\n",
    "        \n",
    "        # At least 6 jets\n",
    "        at_least_one_jet = (ak.count(selected_jets.pt, axis=1) >= 6)\n",
    "        event_filters = event_filters & at_least_one_jet\n",
    "        \n",
    "        # At least 2 bjets\n",
    "\n",
    "        at_least_two_bjets = (ak.count(selected_bjets.pt, axis=1) >= 2)\n",
    "        \n",
    "        event_filters = event_filters & at_least_two_bjets\n",
    "        #print(event_filters)\n",
    "        \n",
    "        # apply event filters\n",
    "        selected_events = events[event_filters]\n",
    "        selected_muons = selected_muons[event_filters]\n",
    "        selected_jets = selected_jets[event_filters]\n",
    "        selected_bjets = selected_bjets[event_filters]\n",
    "        selected_electrons = selected_electrons[event_filters]\n",
    "               \n",
    "        ##### VARIABLES FOR BDT ####\n",
    "        \n",
    "        \n",
    "        #### Calculate HTb\n",
    "        htb = ak.sum(selected_bjets.pt, axis=1)\n",
    "    \n",
    "        \n",
    "        #### Calculate H_t^ratio\n",
    "        selected_jets_sorted = ak.sort(selected_jets.pt, axis=1, ascending=False)\n",
    "        \n",
    "        \n",
    "        third_highest_csv=0.0\n",
    "        htrat=[]\n",
    "        \n",
    "        if len(ak.fields(selected_jets_sorted)) >= 4: \n",
    "            four_leading_jets=selected_jets_sorted[:, :4]\n",
    "            ht_leading_jets=ak.sum(four_leading_jets,axis=1)\n",
    "            other_jets=selected_jets_sorted[:, 4:]\n",
    "            ht_other_jets = ak.sum(other_jets,axis=1)\n",
    "            htrat = ht_other_jets/ht_leading_jets\n",
    "        \n",
    "        #### Calculate Third-highest CSV\n",
    "        \n",
    "        #Sort jets by CSV values \n",
    "        sorted_jets= ak.argsort(selected_jets.btagCSVV2, axis=1)\n",
    "        \n",
    "        #Extract the third-highest CSV value\n",
    "        if len(ak.fields(sorted_jets)) >= 2:\n",
    "            third_highest_csv = sorted_jets[:, 2]\n",
    "        \n",
    "        \n",
    "        for ivar in [ \"pt\", \"eta\" ]:\n",
    "            \n",
    "            hists[f'muon_{ivar}'].fill(\n",
    "                        var=ak.flatten(getattr(selected_muons, ivar)), process=process, variation=\"nominal\", weight=xsec_weight)\n",
    "            hists[f'jets_{ivar}'].fill(\n",
    "                        var=ak.flatten(getattr(selected_jets, ivar)), process=process, variation=\"nominal\", weight=xsec_weight)\n",
    "            hists['nmuons'].fill(var=ak.count(selected_muons.pt, axis=1), process=process, variation=\"nominal\", weight=xsec_weight)\n",
    "            hists['njets'].fill(var=ak.count(selected_jets.pt, axis=1), process=process, variation=\"nominal\", weight=xsec_weight)\n",
    "            hists['nbjets'].fill(var=ak.count(selected_bjets.pt, axis=1), process=process,variation=\"nominal\", weight=xsec_weight)\n",
    "            hists['htb'].fill(var=htb, process=process, variation=\"nominal\", weight=xsec_weight)\n",
    "            hists['htrat'].fill(var=htrat, process=process, variation=\"nominal\", weight=xsec_weight)\n",
    "            hists['third_highest_csv'].fill(var=third_highest_csv, process=process, variation=\"nominal\", weight=xsec_weight)\n",
    "            \n",
    "            njets_values = ak.count(selected_jets.pt, axis=1)\n",
    "            nbjets_values=ak.count(selected_bjets.pt, axis=1)\n",
    "            htrat_values=htrat\n",
    "            htb_values=htb\n",
    "            \n",
    "            if process == \"tttt\":\n",
    "                self.njets_signal_data.extend(njets_values)\n",
    "                self.nbjets_signal_data.extend(nbjets_values)\n",
    "                self.htb_signal_data.extend(htb)\n",
    "                self.htrat_signal_data.extend(htrat)\n",
    "                \n",
    "            elif process == \"ttbar\" or process == \"wjets\" or process == \"dyjets\":\n",
    "                self.njets_background_data.extend(njets_values)\n",
    "                self.nbjets_background_data.extend(nbjets_values)\n",
    "                self.htb_background_data.extend(htb)\n",
    "                self.htrat_background_data.extend(htrat)\n",
    "                \n",
    "            elif process == \"data\":\n",
    "                self.njets_data.extend(njets_values)\n",
    "                self.nbjets_data.extend(nbjets_values)\n",
    "                self.htb_data.extend(htb)\n",
    "                self.htrat_data.extend(htrat)\n",
    "                \n",
    "            output = {\"nevents\": {events.metadata[\"dataset\"]: len(selected_events)}, \"hists\" : hists,\n",
    "        \"njets_signal_data\": self.njets_signal_data,\n",
    "        \"njets_background_data\": self.njets_background_data,\n",
    "        \"nbjets_signal_data\": self.nbjets_signal_data,\n",
    "        \"nbjets_background_data\": self.nbjets_background_data, \n",
    "        \"htb_signal_data\": self.htb_signal_data,\n",
    "        \"htb_background_data\": self.htb_background_data,\n",
    "        \"htrat_signal_data\":self.htrat_signal_data,\n",
    "        \"htrat_background_data\":self.htrat_background_data,\n",
    "        \"njets_data\": self.njets_data,\n",
    "        \"nbjets_data\": self.nbjets_data,\n",
    "        \"htb_data\": self.htb_data,\n",
    "        \"htrat_data\":self.htrat_data}\n",
    "            \n",
    "            return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        \n",
    "             \n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a37346f",
   "metadata": {},
   "source": [
    "Let's make it run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2903d0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e003f90f66094ac994a2d5d0b33ee5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/5722 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f072807cc14977853eadb02f681b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/5564 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:193: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "executor = processor.FuturesExecutor(workers=NUM_CORES)\n",
    "\n",
    "run = processor.Runner(executor=executor, schema=NanoAODSchema, \n",
    "                       savemetrics=True, metadata_cache={}, chunksize=CHUNKSIZE)\n",
    "t0 = time.monotonic()\n",
    "all_histograms, metrics = run(fileset, \"Events\", processor_instance=fourTopAnalysis(DATASET=DATA))\n",
    "exec_time = time.monotonic() - t0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a800c96",
   "metadata": {},
   "source": [
    "Now, we extract the data that we will later use for the BDT process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129bd92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: dyjets__nominal, Number of Events: 36\n",
      "Dataset: wjets__nominal, Number of Events: 96\n",
      "Dataset: tttt__nominal, Number of Events: 30769\n",
      "Dataset: ttbar__nominal, Number of Events: 819169\n",
      "Dataset: data, Number of Events: 14091\n"
     ]
    }
   ],
   "source": [
    "nevents_info = all_histograms[\"nevents\"]\n",
    "for dataset, num_events in nevents_info.items():\n",
    "    print(f\"Dataset: {dataset}, Number of Events: {num_events}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed22e5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'njsig' (list)\n",
      "Stored 'njbkg' (list)\n",
      "Stored 'nbjsig' (list)\n",
      "Stored 'nbjbkg' (list)\n",
      "Stored 'htbsig' (list)\n",
      "Stored 'htbbkg' (list)\n",
      "Stored 'htratsig' (list)\n",
      "Stored 'htratbkg' (list)\n",
      "Stored 'njdata' (list)\n",
      "Stored 'nbjdata' (list)\n",
      "Stored 'htbdata' (list)\n",
      "Stored 'htratdata' (list)\n"
     ]
    }
   ],
   "source": [
    "njsig = all_histograms[\"njets_signal_data\"]\n",
    "njbkg = all_histograms[\"njets_background_data\"]\n",
    "\n",
    "nbjsig = all_histograms[\"nbjets_signal_data\"]\n",
    "nbjbkg = all_histograms[\"nbjets_background_data\"]\n",
    "\n",
    "htbsig = all_histograms[\"htb_signal_data\"]\n",
    "htbbkg = all_histograms[\"htb_background_data\"]\n",
    "\n",
    "htratsig = all_histograms[\"htrat_signal_data\"]\n",
    "htratbkg = all_histograms[\"htrat_background_data\"]\n",
    "\n",
    "njdata = all_histograms[\"njets_data\"]\n",
    "nbjdata = all_histograms[\"nbjets_data\"]\n",
    "htbdata= all_histograms[\"htb_data\"]\n",
    "htratdata = all_histograms[\"htrat_data\"]\n",
    "\n",
    "%store njsig\n",
    "%store njbkg\n",
    "%store nbjsig \n",
    "%store nbjbkg\n",
    "%store htbsig \n",
    "%store htbbkg \n",
    "%store htratsig\n",
    "%store htratbkg \n",
    "\n",
    "%store njdata \n",
    "%store nbjdata\n",
    "%store htbdata\n",
    "%store htratdata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57cef8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"histograms.pkl\", \"wb\") as f: \n",
    "    pickle.dump(all_histograms[\"hists\"], f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d6e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event rate per worker (full execution time divided by NUM_CORES=4): 7.36 kHz\n",
      "event rate per worker (pure processtime): 18.05 kHz\n",
      "amount of data read: 14812.27 MB\n"
     ]
    }
   ],
   "source": [
    "dataset_source = \"/data\" if fileset[\"ttbar__nominal\"][\"files\"][0].startswith(\"/data\") else \"https://xrootd-local.unl.edu:1094\" # TODO: xcache support\n",
    "metrics.update({\"walltime\": exec_time, \"num_workers\": NUM_CORES, \"dataset_source\": dataset_source, \n",
    "                \"n_files_max_per_sample\": N_FILES_MAX_PER_SAMPLE, \n",
    "                \"cores_per_worker\": CORES_PER_WORKER, \"chunksize\": CHUNKSIZE})#\n",
    "\n",
    "print(f\"event rate per worker (full execution time divided by NUM_CORES={NUM_CORES}): {metrics['entries'] / NUM_CORES / exec_time / 1_000:.2f} kHz\")\n",
    "print(f\"event rate per worker (pure processtime): {metrics['entries'] / metrics['processtime'] / 1_000:.2f} kHz\")\n",
    "print(f\"amount of data read: {metrics['bytesread']/1000**2:.2f} MB\")  # likely buggy: https://github.com/CoffeaTeam/coffea/issues/717\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee852690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
